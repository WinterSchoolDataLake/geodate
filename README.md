# Общая документация

# Проект:

Задача реализации варианта поступления потоковых данных в Data Lake и первый анализ ((Apache Kafka или БД) + Apache Spark Streaming + GeoMesa + Apache Cassandra)

## **Цели:**

1. Использование стека технологий — Apache Kafka +Apache Spark Streaming + GeoMesa +  Apache Cassandra — для осуществления анализа пространственно-временного положения абонентов в заданном географическом полигоне. 
2. Определение пикового (максимального) значения нагрузки системы, то есть максимального количества N данных в единицу времени, которое система способна корректно обработать.
3. Изучить варианты поведения системы/Apache Kafka при превышении предельной нагрузки. 

## Назначение:

Созданная система предназначена для определения числа абонентов, находящихся в заданном геополигоне на карте на заданном временном промежутке на основе сгенерированых данных.

## План проекта:

1. На первом компьютере первый разработчик на Python 3.6+ генерирует случайную базу данных пользователей, в которую для каждого пользователя входят их ID, долгота и широта их местоположения (геопозиция) и время последней активности - далее стандартный набор данных пользователя. На этом этапе возможна генерация нескольких стандартных наборов для одного и того же пользователя, которые могут быть как одинаковыми, так и нет.
2. Команда использует Apache Kafka для обмена сообщениями между первым компьютером и вторым. 
3. Второй разработчик на Apache Spark реализует механизм считывания данных из Apache Kafka.
4. В Spark Streaming формируется датафрейм из стандартных наборов пользователей во временном окне в 10 минут.
5. Данные о геопозиции пользователей обрабатываются с помощью geomesa + Apache Spark Streaming, отправляются на 3 компьютер, где сохраняются в NoSQL базу данных по GeoHash индексу. В качестве NoSQL БД используется Apache Cassandra.
6. В результате становится возможным доставать из NoSQL БД данные по произвольному геополигону. А точнее, какие пользователи присутствовали в этом полигоне с 12:00 по 16:00.
7. Команда производит работу с нагрузкой системы: нагружает систему так, чтобы на сервера подавалось слишком много данных, и исследует, ломается ли программа или происходит деградация в обработке данных. Если деградация, то исследует, какая, и уменьшится ли поток обрабатываемых данных.
8. Находится максимальное количество данных, подающихся в единицу времени на Kafka, при котором система способна корректно обрабатывать данные.
9. 

## Требования к системе:

### Требования к техническому оборудованию:

В проекте задействована связка из 3-х ноутбуков, но данная архитектура позволяет использовать сервер в качестве связующего элемента и пользовательских ПК на выходе.

### Требования к программному обеспечению компьютеров:

Python 3.6+, Java, Scala, Apache Kafka, Apache Cassandra, Apache Spark, GeoMesa, Docker.

### Требования, предъявляемые к системе:

1. Spark должен выдавать сформированный датафрейм из пространственно-временных данных абонентов с заданной частотой (10 минут) в систему управления базами данных Cassandra.
2. Необходимо визуализировать сгенерированную и обработанную базу данных абонентов с координатами на карте выбранного геополигона. На карте будут отображены и выделены точки, соответствующие координатам абонента, а в отдельном терминале:
    - номер телефона (он же идентификатор абонента);
    - долготу;
    - широту;
    - время последней активности абонента.
    
## Макет системы:

![Макет.png](https://raw.githubusercontent.com/WinterSchoolDataLake/geodate/master/docs/___(4).png)

## Правила и ограничения:

---

## Дополнительная информация:

[Стейкхолдеры](https://github.com/WinterSchoolDataLake/geodate/blob/master/docs/stakeholder.md)

[Словарь терминов](https://github.com/WinterSchoolDataLake/geodate/blob/master/docs/dictionary.md)

[Доступы к стендам и внешним системам](https://github.com/WinterSchoolDataLake/geodate/blob/master/docs/stand_access.md)
